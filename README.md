# Adversarial Attack Visualization

This repository contains code for training neural networks (Fully Connected, Convolutional, ResNet) and implementing adversarial attacks (L0, L1, L2, Linf). The project also includes methods to visualize the impact of these attacks using K-Nearest Neighbors (KNN) counting and manifold proximity techniques.

## Features

- **Neural Network Training**: Train different types of neural networks including Fully Connected (FC), Convolutional (Conv), and ResNet architectures.
- **Adversarial Attacks**: Implement attacks such as L0, L1, L2, and Linf to evaluate the robustness of trained models.
- **Impact Visualization**: Use KNN counting and manifold proximity methods to visualize how adversarial attacks affect model predictions.

## Requirements

- Python 3.x
- PyTorch
- NumPy
- Matplotlib (for visualization)

## Installation

Clone the repository to your local machine:

```bash
git clone https://github.com/JanullaPolasko/Adversarial-Attack-visualization.git
pip install -r requirements.txt
Install the required packages:
